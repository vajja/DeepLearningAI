{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad96800d-eacf-474c-8e94-4b239266e963",
   "metadata": {},
   "source": [
    "# Prompt Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c986db25-00c0-4496-ba3d-1827c5ae3bc5",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12069b71-c878-4199-8d7b-0ba469294742",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b7c6f4-67c2-4b9c-838f-4ae4c8c48b70",
   "metadata": {},
   "source": [
    "If you would like to view the utils.py file, uncomment the following line and run it. Alternately to view it in an editor, click `file->open` and look for utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "378a2aac-8aba-42c2-b98a-6260e9c866df",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#!cat utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878c8b00-1f82-4ae8-973d-6775e8d1c14f",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>utils.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix - Tips and Help\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3131d-c1e0-4ce9-909b-222063cab03d",
   "metadata": {
    "id": "DC3VBQGs7ggW"
   },
   "source": [
    "## Using the \"user\" and \"assistant\" roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a39424b-ddc4-4a99-969d-270a06adf472",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Who wrote the book Charlotte's Web?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
     ]
    }
   ],
   "source": [
    "question = \"Who wrote the book Charlotte's Web?\"\n",
    "\n",
    "prompt = (\n",
    "    \"<|begin_of_text|>\"                              # start of prompt\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"       # user header\n",
    "    f\"{question}\"                                    # user input\n",
    "    \"<|eot_id|>\"                                     #end of turn\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"  #assistant header\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccfba2fe-8fa3-41b4-b91c-2f66dc6bfe5f",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The book \"Charlotte's Web\" was written by E.B. White.\n"
     ]
    }
   ],
   "source": [
    "from  utils import llama31\n",
    "response = llama31(prompt,8)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7ffce6-514a-4e4a-acdf-ca65e49d2627",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"id\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"o6gA9H1-2j9zxn-96d4d207ff72ce34\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"object\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"text.completion\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"created\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m1754884768\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"model\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"prompt\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m[],\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"choices\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m[\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"text\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"\\n\\nThe book \\\"Charlotte's Web\\\" was written by E.B. White.\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"finish_reason\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"stop\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"seed\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m10647399084346800000\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"logprobs\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34mnull\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"index\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m}\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"usage\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"prompt_tokens\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m16\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"completion_tokens\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m17\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"total_tokens\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m33\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"cached_tokens\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m}\u001b[37m\u001b[39;49;00m\n",
      "}\u001b[37m\u001b[39;49;00m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import cprint\n",
    "response = llama31(prompt,8, raw=True)\n",
    "\n",
    "cprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8160c83-47d3-42b5-92fb-86f5fd97af51",
   "metadata": {},
   "source": [
    "# Multi-turn chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c191c7-e158-4865-a80d-fade3d145d58",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "follow_up_question = \"Three best quotes in it\"\n",
    "follow_up_prompt = (\n",
    "    \"<|begin_of_text|>\"                              # start of prompt\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"        # past  \n",
    "    f\"{question}\"                                     # past\n",
    "    \"<|eot_id|>\"                                      # past\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"   # past\n",
    "    f\"{response}\"                                     # past\n",
    "    \"<|eot_id|>\"                                      # past\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"       # new\n",
    "    f\"{follow_up_question}\"                          # new\n",
    "    \"<|eot_id|>\"                                     # new\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"  # new\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e798493a-e9c8-4d96-8baf-f18c8bc8d2c6",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three of the most famous and beloved quotes from \"Charlotte's Web\" by E.B. White:\n",
      "\n",
      "1. **\"Some pigs are smarter than others. Clear the way for a genius.\"** - Charlotte's Web, Chapter 1\n",
      "\n",
      "This quote sets the tone for the story, highlighting the unique bond between Charlotte and Wilbur, and showcasing Charlotte's intelligence and wit.\n",
      "\n",
      "2. **\"It is not often that someone comes along who is a true friend and a good writer. Charlotte was both.\"** - Charlotte's Web, Chapter 1\n",
      "\n",
      "This quote beautifully captures the essence of Charlotte's character and her special friendship with Wilbur. It's a testament to the power of friendship and the impact one person can have on another's life.\n",
      "\n",
      "3. **\"Where there is love, there is life.\"** - Charlotte's Web, Chapter 14\n",
      "\n",
      "This quote is a poignant reflection on the themes of love, friendship, and the cycle of life. It's a beautiful reminder that even in the face of adversity, love and connection can bring hope and meaning to our lives.\n",
      "\n",
      "These quotes have become iconic in children's literature and continue to inspire readers of all ages with their wisdom, kindness, and beauty.\n"
     ]
    }
   ],
   "source": [
    "follow_up_response = llama31(follow_up_prompt)\n",
    "print(follow_up_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb293be0-612e-48df-b74a-d4d2d98ca8b2",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are three of the most famous and beloved quotes from \"Charlotte's Web\" by E.B. White:\n",
       "\n",
       "1. **\"Some pigs are smarter than others. Clear the way for a genius.\"** - Charlotte's Web, Chapter 1\n",
       "\n",
       "This quote sets the tone for the story, highlighting the unique bond between Charlotte and Wilbur, and showcasing Charlotte's intelligence and wit.\n",
       "\n",
       "2. **\"It is not often that someone comes along who is a true friend and a good writer. Charlotte was both.\"** - Charlotte's Web, Chapter 1\n",
       "\n",
       "This quote beautifully captures the essence of Charlotte's character and her special friendship with Wilbur. It's a testament to the power of friendship and the impact one person can have on another's life.\n",
       "\n",
       "3. **\"Where there is love, there is life.\"** - Charlotte's Web, Chapter 14\n",
       "\n",
       "This quote is a poignant reflection on the themes of love, friendship, and the cycle of life. It's a beautiful reminder that even in the face of adversity, love and connection can bring hope and meaning to our lives.\n",
       "\n",
       "These quotes have become iconic in children's literature and continue to inspire readers of all ages with their wisdom, kindness, and beauty."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(follow_up_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6036cfb-876b-4487-8325-33f03b4ff085",
   "metadata": {},
   "source": [
    "#### Without message history\n",
    "This is not in the video, but you can try the same prompt *Without* including history and see the models responds with three quotes - but not from the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "899eba88-632f-4ff9-bae6-8a5831284bfa",
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "Here are three of the most inspiring and thought-provoking quotes:\n",
       "\n",
       "1. **\"Believe you can and you're halfway there.\"** - Theodore Roosevelt\n",
       "\n",
       "This quote emphasizes the importance of having a positive mindset and believing in oneself. It's a reminder that our thoughts and attitudes can shape our reality and help us achieve our goals.\n",
       "\n",
       "2. **\"The future belongs to those who believe in the beauty of their dreams.\"** - Eleanor Roosevelt\n",
       "\n",
       "This quote highlights the power of imagination and the importance of having a clear vision for our lives. It encourages us to dream big and believe in the possibility of achieving our goals.\n",
       "\n",
       "3. **\"It does not matter how slowly you go as long as you do not stop.\"** - Confucius\n",
       "\n",
       "This quote reminds us that progress is often slow and incremental, but it's the consistent effort and perseverance that ultimately lead to success. It encourages us to stay focused and motivated, even in the face of challenges and setbacks.\n",
       "\n",
       "I hope you find these quotes inspiring and thought-provoking!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Three Best quotes\"\n",
    "prompt = (\n",
    "    \"<|begin_of_text|>\"  \n",
    "    \"<|start_header_id|>user<|end_header_id|>\"\n",
    "    f\"{question}\"\n",
    "    \"<|eot_id|>\"\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    ")\n",
    "response = llama31(prompt,8)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0f383-4115-44d5-9a58-62463ec5cbfb",
   "metadata": {},
   "source": [
    "## Using \"system\" role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fed0d3ce-a42b-446b-8a88-a4cefb185acc",
   "metadata": {
    "height": 336
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "* \"Champions are made from something they have deep inside them - a desire, a dream, a vision.\" - Muhammad Ali\n",
       "* \"It's not whether you get knocked down, it's whether you get up.\" - Vince Lombardi\n",
       "* \"Hard work, dedication, and a willingness to learn are the keys to success in any field, including sports.\" - Michael Jordan"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Three Great quotes\"\n",
    "system_message = (\n",
    "    \"You are an expert in quotes about sports \" \n",
    "    \"You provide just the quotes and no commentary. \"\n",
    "    \"Reply in markdown\"\n",
    ")\n",
    "\n",
    "prompt = (\n",
    "    \"<|begin_of_text|>\"\n",
    "    \"<|start_header_id|>system<|end_header_id|>\"\n",
    "    f\"{system_message}\"\n",
    "    \"<|eot_id|>\"    \n",
    "    \"<|start_header_id|>user<|end_header_id|>\"\n",
    "    f\"{question}\"\n",
    "    \"<|eot_id|>\"\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    ")\n",
    "response = llama31(prompt,70)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f5c210f-080b-4fe1-8a7b-7ff38d0ae9c8",
   "metadata": {
    "height": 336
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "* \"The only way to do great work is to love what you do.\" - Tom Landry\n",
       "* \"Don't count the days, make the days count.\" - Muhammad Ali\n",
       "* \"You miss 100% of the shots you don't take.\" - Wayne Gretzky"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "follow_up_question = \"three more\"\n",
    "follow_up_prompt = (\n",
    "    \"<|begin_of_text|>\"\n",
    "    \"<|start_header_id|>system<|end_header_id|>\"      # system\n",
    "    f\"{system_message}\"                               # system\n",
    "    \"<|eot_id|>\"                                      # system\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"        # past\n",
    "    f\"{question}\"                                     # past\n",
    "    \"<|eot_id|>\"                                      # past\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"   # past\n",
    "    f\"{response}\"                                     # past\n",
    "    \"<|eot_id|>\"                                      # past\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"         # new\n",
    "    f\"{follow_up_question}\"                            # new     \n",
    "    \"<|eot_id|>\"                                       # new\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"    # new\n",
    ")\n",
    "response = llama31(follow_up_prompt)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139ecab0-a233-414e-a62d-dfb7b6bfbeef",
   "metadata": {},
   "source": [
    "# Chat with Llama using higher-level message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67920bea-5b75-4a42-a3a0-0aae77bc0842",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The book \"Charlotte's Web\" was written by E.B. White.\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"<|begin_of_text|>\"                              # start of prompt\n",
    "    \"<|start_header_id|>user<|end_header_id|>\"       # user header\n",
    "    \"Who wrote the book Charlotte's Web?\"                                    # user input\n",
    "    \"<|eot_id|>\"                                     #end of turn\n",
    "    \"<|start_header_id|>assistant<|end_header_id|>\"  #assistant header\n",
    ")\n",
    "response = llama31(prompt,8)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58aa6676-3f4b-4d26-b679-ce392ec73845",
   "metadata": {
    "height": 149,
    "id": "nw9GEik8PWrx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book \"Charlotte's Web\" was written by E.B. White.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Who wrote the book Charlotte's Web?\"\n",
    "    }\n",
    "  ]\n",
    "response = llama31(messages,8)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67d3c1da-383e-423c-a1e8-d2c355febde0",
   "metadata": {
    "height": 404
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three notable quotes from \"Charlotte's Web\":\n",
      "\n",
      "1. \"It is not often that someone comes along who is a true friend and a good writer. Charlotte was both.\" \n",
      "2. \"Where there is much light, the shadows are deep.\" \n",
      "3. \"It's not often that someone comes along who has a real need for a friend.\"\n"
     ]
    }
   ],
   "source": [
    "follow_up_question = \"Three Best quotes\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are an terse expert in children's literature\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Who wrote the book Charlotte's Web?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": response\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": follow_up_question\n",
    "    }\n",
    "  ]\n",
    "\n",
    "response = llama31(messages,8)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01b98689-fa40-4466-86f7-4ac17e206d81",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.messages = []\n",
    "        if system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "    def generate(self, user_question, model=8, temp=0):\n",
    "        self.messages.append({\"role\": \"user\", \"content\":user_question})\n",
    "        response = llama31(self.messages, model, temperature=temp)\n",
    "        self.messages.append({\"role\":\"assistant\", \"content\":response})\n",
    "        return response\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7479e19b-8270-4368-9bd9-cdeed5ed5664",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E.B. White wrote the book \"Charlotte\\'s Web\".'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"You are a terse expert in Childrens literature.\" \n",
    "conv = Conversation(system_message)\n",
    "conv.generate(\"Who wrote the book Charlotte's Web?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da3f5c43-262a-4b40-b00f-e6af7269e3eb",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are three quotes from \"Charlotte's Web\":\n",
       "\n",
       "1. \"Some people have a way with words, and other people... don't.\" \n",
       "2. \"It's not often that someone comes along who is a true friend and a good writer. Charlotte was both.\"\n",
       "3. \"Where there is much light, the shadows are deep.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = conv.generate(\"What are three quotes\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be4e57bc-f77d-40f2-9b92-36c4dd8f8756",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a terse expert in Childrens literature.'},\n",
       " {'role': 'user', 'content': \"Who wrote the book Charlotte's Web?\"},\n",
       " {'role': 'assistant',\n",
       "  'content': 'E.B. White wrote the book \"Charlotte\\'s Web\".'},\n",
       " {'role': 'user', 'content': 'What are three quotes'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Here are three quotes from \"Charlotte\\'s Web\":\\n\\n1. \"Some people have a way with words, and other people... don\\'t.\" \\n2. \"It\\'s not often that someone comes along who is a true friend and a good writer. Charlotte was both.\"\\n3. \"Where there is much light, the shadows are deep.\"'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d68ae5-31e7-4ebc-9100-88be9470ee45",
   "metadata": {
    "id": "5QntbEMl9uO5"
   },
   "source": [
    "## Multi-lingual Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4842cb63-d0b6-487c-b9ed-38f6e86b7ea0",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are 3 basic phrases in 8 languages:\n",
       "\n",
       "**English**\n",
       "1. Hello - Hello\n",
       "2. Thank you - Thank you\n",
       "3. Goodbye - Goodbye\n",
       "\n",
       "**German**\n",
       "1. Hallo - Hello\n",
       "2. Danke - Thank you\n",
       "3. Auf Wiedersehen - Goodbye\n",
       "\n",
       "**French**\n",
       "1. Bonjour - Hello\n",
       "2. Merci - Thank you\n",
       "3. Au revoir - Goodbye\n",
       "\n",
       "**Italian**\n",
       "1. Ciao - Hello/Goodbye\n",
       "2. Grazie - Thank you\n",
       "3. Arrivederci - Goodbye\n",
       "\n",
       "**Portuguese**\n",
       "1. Ol√° - Hello\n",
       "2. Obrigado/Obrigada - Thank you (male/female)\n",
       "3. Tchau - Goodbye\n",
       "\n",
       "**Hindi**\n",
       "1. ‡§®‡§Æ‡§∏‡•ç‡§§‡•á (Namaste) - Hello\n",
       "2. ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶ (Dhanyavad) - Thank you\n",
       "3. ‡§Ö‡§≤‡§µ‡§ø‡§¶‡§æ (Alvida) - Goodbye\n",
       "\n",
       "**Spanish**\n",
       "1. Hola - Hello\n",
       "2. Gracias - Thank you\n",
       "3. Adi√≥s - Goodbye\n",
       "\n",
       "**Thai**\n",
       "1. ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ (Sawatdee) - Hello\n",
       "2. ‡∏Ç‡∏≠‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì (Khop Khun Krap) - Thank you (male)\n",
       "3. ‡∏Ç‡∏≠‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì (Khop Khun Kha) - Thank you (female)\n",
       "4. ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö/‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ (Sawatdee Krap/Sawatdee Ka) - Goodbye (male/female)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = (\n",
    "    \"Answer in 8 languages: English, German, French, Italian,\" \n",
    "    \"Portuguese, Hindi, Spanish, and Thai\"\n",
    ")\n",
    "ml_conv = Conversation(system_message)\n",
    "response = ml_conv.generate(\"3 basic phrases\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2bd3d8-c291-4edd-9b60-8a3faffc5100",
   "metadata": {},
   "source": [
    "## Chatbot App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dda1354e-b37b-491e-a7f5-c2bb397d14d5",
   "metadata": {
    "height": 523
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a Python script for a Gradio chatbot app that you can run within a Jupyter notebook:\n",
      "\n",
      "```python\n",
      "import gradio as gr\n",
      "\n",
      "# Initialize the conversation with a system message\n",
      "conversation = Conversation(system=\"You are an expert in literature. You provide brief replies.\")\n",
      "\n",
      "# Define a function to handle user input\n",
      "def chatbot(user_input, model_size, temperature):\n",
      "    # Generate a response using the Conversation class\n",
      "    response = conversation.generate(user_input, model=model_size, temp=temperature)\n",
      "    return response\n",
      "\n",
      "# Create a Gradio interface for the chatbot\n",
      "demo = gr.Interface(\n",
      "    fn=chatbot,\n",
      "    inputs=[\n",
      "        gr.Textbox(label=\"User Input\"),\n",
      "        gr.Radio(label=\"Model Size\", choices=[8, 70, 405], value=8),\n",
      "        gr.Slider(label=\"Temperature\", minimum=0, maximum=1, step=0.1, value=0)\n",
      "    ],\n",
      "    outputs=gr.Textbox(label=\"Chatbot Response\"),\n",
      "    title=\"Literature Expert Chatbot\",\n",
      "    description=\"Ask a question about literature and get a brief response from an expert.\"\n",
      ")\n",
      "\n",
      "# Launch the Gradio app\n",
      "demo.launch()\n",
      "```\n",
      "\n",
      "To run this script within a Jupyter notebook, simply copy and paste the code into a cell and execute it. The Gradio app will launch in a new window, allowing you to interact with the chatbot.\n",
      "\n",
      "Note: Make sure you have the `gradio` library installed in your Jupyter notebook environment. You can install it using `!pip install gradio` or `!conda install -c conda-forge gradio`.\n"
     ]
    }
   ],
   "source": [
    "code_query = \"\"\"\n",
    "I need a Python script for a Gradio chatbot app that should be run\n",
    "within a Jupyter notebook.\n",
    "1) When calling the LLM, use this class, which is already defined,\n",
    "    dont redefine it:\n",
    "class Conversation:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.messages = []\n",
    "        if system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def generate(self, user_question, model=8, temp=0):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_question})\n",
    "        response = llama31(self.messages, model, temperature=temp)  \n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        return response\n",
    "2) initialize the class with a system message of:\n",
    "    \"You are an expert in liturature. You provide brief replies\"\n",
    "3) the llama() function is defined like this:\n",
    "    def llama(prompt_or_messages, model_size=8, \n",
    "              temperature=0, raw=False, debug=False):\n",
    "    and returns a reponse in a string. Don't redefine this.\n",
    "    valid model sizes are 8, 70 and 405.\n",
    "\"\"\"\n",
    "coder_system_message = (\n",
    "    \"You are an expert writing python Gradio chatbots\" \n",
    ")\n",
    "coder_conv = Conversation(coder_system_message)\n",
    "response = coder_conv.generate(code_query, 405)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dd04e2-0986-41f7-9b44-21459445d3d8",
   "metadata": {
    "height": 659
   },
   "outputs": [],
   "source": [
    "# This is the code generated by Llama in the video\n",
    "# Your response to the above prompt may differ - try running your response as well!\n",
    "# note, the final line was hand edited to add \"server_name=\"0.0.0.0\" to run in the course environment\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "# Initialize the conversation with a system message\n",
    "conversation = Conversation(\"You are an expert in literature. You provide brief replies.\")\n",
    "\n",
    "# Define a function to generate a response to the user's input\n",
    "def generate_response(user_input, model_size, temperature):\n",
    "    try:\n",
    "        model_size = int(model_size)\n",
    "        if model_size not in [8, 70, 405]:\n",
    "            return \"Invalid model size. Please choose from 8, 70, or 405.\"\n",
    "        temperature = float(temperature)\n",
    "        if temperature < 0 or temperature > 1:\n",
    "            return \"Invalid temperature. Please choose a value between 0 and 1.\"\n",
    "        response = conversation.generate(user_input, model=model_size, temp=temperature)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Create a Gradio interface for the chatbot\n",
    "demo = gr.Interface(\n",
    "    fn=generate_response,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"User Input\"),\n",
    "        gr.Radio(label=\"Model Size\", choices=[\"8\", \"70\", \"405\"]),\n",
    "        gr.Slider(label=\"Temperature\", minimum=0, maximum=1, step=0.1, value=0)\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Response\"),\n",
    "    title=\"Literature Expert Chatbot\",\n",
    "    description=\"Ask a question about literature and get a brief response from an expert.\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio app\n",
    "demo.launch(server_name=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57bf3f4-63b5-45c7-943d-432e25376dd4",
   "metadata": {},
   "source": [
    "# A few more examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e79366c-678e-4f95-9bc7-520296fd9d54",
   "metadata": {
    "id": "Fz1IIJXajf77"
   },
   "source": [
    "## Compare with different sized Llama chat models\n",
    "\n",
    "By default, the llama31 call uses the Llama 3.1 8B Instruct model. To see how the 70B or 405B model responds, simply pass 70 or 405 after prompt. For example, let compare how the 3 different sized Llama 3.1 chat models respond to the question about a quote in Hemingway's classic The Old Man and the Sea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b420f914-9100-404d-bb66-22bc362774ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 149,
    "id": "f_WT9xQwaFbw",
    "outputId": "e40261ab-2c49-43fe-ec55-e1e5f658b26a"
   },
   "outputs": [],
   "source": [
    "question = \"The quote that starts with 'Everything about him is old' in The Old Man and the Sea\"\n",
    "\n",
    "prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "\n",
    "response = llama31(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8019206b-dc6d-4a10-92d1-21b7dd30f528",
   "metadata": {
    "id": "OzlDWmD9koc9"
   },
   "source": [
    "If you like Hemingway, you know Llama 3.1 8B is hallucinating a bit, and \"old before they were young\"? Now try to see if 70B does better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d73d605-872a-417a-ab06-4854670f2966",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "_pZ80oupaFeX",
    "outputId": "ea30acaf-8c39-49fb-b9ba-34cc1f08610b"
   },
   "outputs": [],
   "source": [
    "response = llama31(prompt, 70)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5812ce-a099-47fc-b57b-e233c40e9498",
   "metadata": {
    "id": "Rnyukk3GlHAX"
   },
   "source": [
    "The response makes more sense, but definitely not Hemingway would've written. In fact, it'd hurt the eyes of his fans. Let's hope 405 will cure the pain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad1bace-7b20-429f-bb56-5b542c8a6567",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "dIHVm7ralEo0",
    "outputId": "b72f8dc8-6142-46a2-f25c-73c6d5f168a2"
   },
   "outputs": [],
   "source": [
    "response = llama31(prompt, 405)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b25935-0914-485b-86dc-3d9f11398a98",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
